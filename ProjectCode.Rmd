---
title: "Project"
author: "Katy Miles"
date: "`r Sys.Date()`"
output: html_document
---
# Implementing Solutions to Label Switching for Bootstrap of EM Estimates

## Project Outline

-   Code, in Rcpp, the proposed stratified bootstrap method [Done]
-   Code, in Rcpp, the proposed separated bootstrap method
-   Code, in Rcpp, the proposed label switching adjustment, and then perform parametric bootstrap.
-   Code, in Rcpp, regular parametric bootstrap method
-   Obtain EM algorithm estimates for simulated data from a chosen mixture mode
-   Compare results through tables and graphs
-   Summarize where certain methods fail, succeed, and possible use cases for each

# EM algorithm

```{Rcpp}
#include <RcppArmadillo.h>
// [[Rcpp::depends(RcppArmadillo)]]
using namespace Rcpp;
using namespace arma;

//[[Rcpp::export]]
List em_norm(NumericVector y, NumericVector p, NumericVector theta, 
             bool classes = false) {
  int n = y.size();
  NumericVector w1_tot(n);
  NumericVector w2_tot(n);
  double mu1 = theta[0];
  double mu2 = theta[1];
  double p1 = p[0];
  double p2 = p[1];
  for (int i = 0; i < 50; i++) {
      // E
      NumericVector w1 = p1 * dnorm(y, mu1);
      NumericVector w2 = p2 * dnorm(y, mu2);

      w1_tot = w1 / (w1 + w2);
      w2_tot = w2 / (w1 + w2);
      
      //M
      mu1 = sum(w1_tot * y) / sum(w1_tot);
      mu2 = sum(w2_tot * y) / sum(w2_tot);
      p1 = sum(w1_tot)/n;
      p2 = sum(w2_tot)/n;
  }
  NumericVector p_hat = {p1, p2};
  NumericVector theta_hat = {mu1, mu2};
  if (classes) {
      return List::create(p_hat, theta_hat, w1_tot, w2_tot);
  }
  return List::create(p_hat, theta_hat);
}


namespace helper{
  NumericVector em_helper(NumericVector y, NumericVector p, NumericVector theta, 
               bool classes = false) {
    int n = y.size();
    NumericVector w1_tot(n);
    NumericVector w2_tot(n);
    double mu1 = theta[0];
    double mu2 = theta[1];
    double p1 = p[0];
    double p2 = p[1];
    for (int i = 0; i < 50; i++) {
        // E
        NumericVector w1 = p1 * dnorm(y, mu1);
        NumericVector w2 = p2 * dnorm(y, mu2);
  
        w1_tot = w1 / (w1 + w2);
        w2_tot = w2 / (w1 + w2);
        
        //M
        mu1 = sum(w1_tot * y) / sum(w1_tot);
        mu2 = sum(w2_tot * y) / sum(w2_tot);
        p1 = sum(w1_tot)/n;
        p2 = sum(w2_tot)/n;
    }
    NumericVector ests = {p1, p2, mu1, mu2};
    NumericVector w_tot = cbind(w1_tot, w2_tot);
    if (classes) {
        return cbind(ests, w_tot);
    }
    return ests;
  }
}

//[[Rcpp::export]]
NumericVector stratBoot(NumericVector data, NumericVector classes, 
                        NumericVector params, int iterations) {
  NumericVector theta = params[Range(2,3)];
  NumericVector p = params[Range(0,1)];
  NumericVector result(0);
  int c = p.size();
  // Find the cluster proportions
  for (int b = 0; b < iterations; b++) {
    // Create bootstrap clusters
    NumericVector fullSample(0);
    for (int i = 0; i < c; i++) {
      NumericVector clusterSample(0);
      for (int j = 0; j < classes.size(); j++) {
        if (classes[j] == i + 1) {
          clusterSample.push_back(data[j]);
        }
      }
      if (clusterSample.size() > 0) {
        NumericVector bootSample = sample(clusterSample, p[i]*data.size(), true);
        for (int b = 0; b < bootSample.size(); b++) {
          fullSample.push_back(bootSample[b]);
        }
      }
    }
    
    // EM algorithm
    NumericVector em_eval = helper::em_helper(fullSample, p, theta);
    for (int i = 0; i < em_eval.length(); i++) {
      result.push_back(em_eval[i]);
    }
  }
  return result;
}
```


```{r}
# Stratified bootstrap:  R version
strtBoot = function(data, classes, params, iterations) {
  theta = params[3:4]
  p = params[1:2]
  result = c()
  c = length(p)
  # Find the cluster proportions
  for (b in 1:iterations) {
    # Create bootstrap clusters
    fullSample = c()
    for (i in 1:c) {
      clusterSample = c()
      for (j in 1:length(classes)) {
        if (classes[j] == i) {
          clusterSample = append(clusterSample, data[j])
        }
      }
      if (length(clusterSample) > 0) {
        bootSample = sample(clusterSample, p[i]*length(data), TRUE)
        fullSample = append(fullSample, bootSample)
      }
    }
    
    # EM algorithm
    result = rbind(result, unlist(em_norm(fullSample, p, theta)))
  }
  return(result)
}

regularBoot = function(data, params, iterations) {
  s = data
  theta = matrix(nrow = 0, ncol = 4)
  
  for (j in 1:iterations) {
    # Get EM estimates 
    theta = rbind(theta, unlist(em_norm(s, params[1:2], params[3:4])))
    
    # Increment j
    s = as.matrix(sample(data, length(data), replace = TRUE))
  }
  return(theta)
}
```


```{Rcpp}
#include <RcppArmadillo.h>
#include <bits/stdc++.h> 

// [[Rcpp::depends(RcppArmadillo)]]
using namespace Rcpp;
using namespace arma;
using namespace std;

namespace helper{ 
  NumericMatrix findPermutations(IntegerVector& c, int n) { 
    NumericVector perm(4);
    // Sort the given array 
    sort(c.begin(), c.end()); 
    // Find all possible permutations 
    do {
      for (int i = 0; i < n; i++) { 
        perm.push_back(c[i]); 
      } 
    } while (next_permutation(c.begin(), c.end()));
    NumericMatrix toReturn( c.size() , n , perm.begin() );
    return toReturn;
  }
  arma::vec perm_sort(arma::vec x, arma::vec y) {
      return x(arma::sort_index(y));
  }
}

//[[Rcpp::export]]
vec complh(int n, vec theta_hat, vec p_hat) {
  // Generating sample
  int m = theta_hat.size();
  NumericVector x(n);
  NumericMatrix z(m, n);
  IntegerVector classes =  seq(1, m);
  NumericVector prop(m);
  prop[0] = p_hat[0];
  prop[1] = p_hat[1];
  for (int i = 0; i < n; i++) {
    IntegerVector j = sample(classes, 1, prop);
    if (j[0] ==1) {
      z(1,i) = 1;
    } else {
      z(1,i) = 0;
    }
    if (j[0] == 2) {
      z(2,i) = 1;
    } else {
      z(2,i) = 0;
    }
    x[i] = R::rnorm(theta_hat[j[0]], 1);
  }
  // Label Adjustment using complete log likelihood
  NumericMatrix perm = helper::findPermutations(classes, m);

  double ratio_sum = -10000000;
  NumericVector ratio(n);
  int max_perm = 0;
  for (int k = 0; k < perm.nrow(); k++) {
    NumericVector p = perm(k , _ );
    for (int i = 0; i < n; i++) {
      int num = 0;
      for (int j = 0; j < m; j++) {
        double mean = theta_hat[p[j]];
        double like = R::dnorm(x[i], mean, 1, 0);
        double eval = z(j,i)*log(p_hat[p[j]]*like);
        num = num + eval;
      }
      ratio[i] = num;
    }
    if (sum(ratio) > ratio_sum) {
      ratio_sum = sum(ratio);
      max_perm = k;
    }
  }
  vec y = perm(max_perm, _);
  vec sorted_p = helper::perm_sort(p_hat, y);
  vec sorted_theta = helper::perm_sort(theta_hat, y);
  return join_cols(sorted_p, sorted_theta);
}

```

```{r}
fake_data = as.data.frame(matrix(c(x,label), ncol = 2))
colnames(fake_data) = c("Value", "Label")
fake_data = rowid_to_column(fake_data)
fake_data = fake_data %>%
  mutate(Label = as.factor(Label)) 

ggplot() + 
  geom_point(aes(Value, rowid, color = Label), fake_data) +
  theme_minimal() + 
  geom_text(x=3, y=30, label="Log-Likelihood = -412.6700")


fake_data = fake_data %>%
  mutate(Label = ifelse(Label == "1", "2", "1"))
ggplot() + 
  geom_point(aes(Value, rowid, color = Label), fake_data) +
  theme_minimal() + 
  annotate("text", x=8, y=13, label= "Log-Likelihood = -412.6700") 

likelihood = function(x, p, theta) {
  return(sum(log(p[1]*dnorm(x, theta[1]) + p[2]*dnorm(x, theta[2]))))
}
```


```{r}
library(tidyverse)
regList = list()
stratList = list()
adjList = list()
for (j in 1:100) {
  # Simulate Data
  n = 100
  true_p = c(.5,.5)
  true_theta = c(0, 2)
  p_binom = rbinom(n, 1, true_p[1])
  data = (p_binom)*rnorm(n, true_theta[1]) + (1 - p_binom)*rnorm(n, true_theta[2])
  
  # Get initial values from kmeans
  initial_theta = sort(kmeans(data, 2)$centers[,1])
  initial_p = sort(kmeans(data, 2)$size / length(data))
  
  # Perform EM
  em_result = em_norm(data, initial_p, initial_theta, classes = TRUE)
  theta_hat = em_result[[2]]
  p_hat = em_result[[1]]
  
  # Set number of iterations
  iterations = 100
  
  # Perform Non Parametric Bootstrap
  regBoot = regularBoot(data, params = c(p_hat, theta_hat), iterations)
  
  # Perform Parametric Bootstrap with Label Adjustment
  adjBoot = matrix(ncol = 4, nrow = iterations)
  for (i in 1:iterations) {
    # Take sample
    p_binom = rbinom(n, 1, p_hat[1])
    sample = (p_binom)*rnorm(n, theta_hat[1]) + (1 - p_binom)*rnorm(n,theta_hat[2])
    
    # Get estimates
    em = em_norm(sample, p_hat, theta_hat, classes = FALSE)
    
    # Label Adjustment
    adjBoot[i,] = complh(n, em[[2]], em[[1]])
  }
  
  # Perform Stratified Bootstrap
  w2_tot = em_result[[4]]
  w1_tot = em_result[[3]]
  
  df = data.frame(w1_tot, 
             w2_tot)
  df = df %>%
    rowwise() %>%
    mutate(Classification = ifelse(w1_tot == max(w1_tot, w2_tot), 1, 2))
  
  strtBoot = matrix(stratBoot(data, df$Classification, c(p_hat, theta_hat), iterations), nrow = iterations)
  regCI = c()
  adjCI = c()
  stratCI = c()
  # Get quantile CI
  for (i in 1:4) {
    regCI = rbind(regCI, quantile(regBoot[,i], c(.025,.975)))
    adjCI = rbind(adjCI, quantile(adjBoot[,i], c(.025, .975)))
    stratCI = rbind(stratCI, quantile(strtBoot[,i], c(.025,.975)))
  }
  regList = append(regList, list(regCI))
  adjList = append(adjList, list(adjCI))
  stratList = append(stratList, list(stratCI))
}
```

1000 Bootstrap runs, n = 200

Scenario 1: $$p_1 = 0.5, p_2 = 0.5, \mu_1 = 0, mu_2 = 0.5$$

```{r}
regCoverage = numeric(4)
stratCoverage = numeric(4)
adjCoverage = numeric(4)
for (j in 1:4) {
  params = c(.5,.5,0,.5)
  coverage = numeric(100)
  for (i in 1:100) {
    CI = regList[[i]][j,]
    coverage[i] = ifelse(CI[1] < params[j] && CI[2] > params[j], 1, 0)
  }
  regCoverage[j] = sum(coverage)
  
  coverage = numeric(100)
  for (i in 1:100) {
    CI = adjList[[i]][j,]
    coverage[i] = ifelse(CI[1] < params[j] && CI[2] > params[j], 1, 0)
  }
  adjCoverage[j] = sum(coverage)
  
  coverage = numeric(100)
  for (i in 1:100) {
    CI = stratList[[i]][j,]
    coverage[i] = ifelse(CI[1] < params[j] && CI[2] > params[j], 1, 0)
  }
  stratCoverage[j] = sum(coverage)
}

table = rbind(regCoverage, rbind(adjCoverage, stratCoverage))
colnames(table) = c("P1", "P2", "Theta1", "Theta2")
knitr::kable(table)
```

Scenario 2: $$p_1 = 0.5, p_2 = 0.5, \mu_1 = 0, mu_2 = 1$$

```{r}
regCoverage = numeric(4)
stratCoverage = numeric(4)
adjCoverage = numeric(4)
for (j in 1:4) {
  params = c(.5,.5,0,1)
  coverage = numeric(100)
  for (i in 1:100) {
    CI = regList[[i]][j,]
    coverage[i] = ifelse(CI[1] < params[j] && CI[2] > params[j], 1, 0)
  }
  regCoverage[j] = sum(coverage)
  
  coverage = numeric(100)
  for (i in 1:100) {
    CI = adjList[[i]][j,]
    coverage[i] = ifelse(CI[1] < params[j] && CI[2] > params[j], 1, 0)
  }
  adjCoverage[j] = sum(coverage)
  
  coverage = numeric(100)
  for (i in 1:100) {
    CI = stratList[[i]][j,]
    coverage[i] = ifelse(CI[1] < params[j] && CI[2] > params[j], 1, 0)
  }
  stratCoverage[j] = sum(coverage)
}

table = rbind(regCoverage, rbind(adjCoverage, stratCoverage))
colnames(table) = c("P1", "P2", "Theta1", "Theta2")
knitr::kable(table)
```

Scenario 3: $$p_1 = 0.5, p_2 = 0.5, \mu_1 = 0, mu_2 = 2$$

```{r}
regCoverage = numeric(4)
stratCoverage = numeric(4)
adjCoverage = numeric(4)
for (j in 1:4) {
  params = c(.5,.5,0,2)
  coverage = numeric(100)
  for (i in 1:100) {
    CI = regList[[i]][j,]
    coverage[i] = ifelse(CI[1] < params[j] && CI[2] > params[j], 1, 0)
  }
  regCoverage[j] = sum(coverage)
  
  coverage = numeric(100)
  for (i in 1:100) {
    CI = adjList[[i]][j,]
    coverage[i] = ifelse(CI[1] < params[j] && CI[2] > params[j], 1, 0)
  }
  adjCoverage[j] = sum(coverage)
  
  coverage = numeric(100)
  for (i in 1:100) {
    CI = stratList[[i]][j,]
    coverage[i] = ifelse(CI[1] < params[j] && CI[2] > params[j], 1, 0)
  }
  stratCoverage[j] = sum(coverage)
}

table = rbind(regCoverage, rbind(adjCoverage, stratCoverage))
colnames(table) = c("P1", "P2", "Theta1", "Theta2")
knitr::kable(table)
```

1000 Bootstrap runs, n = 50

Scenario 1: $$p_1 = 0.5, p_2 = 0.5, \mu_1 = 0, mu_2 = 0.5$$

Scenario 2: $$p_1 = 0.5, p_2 = 0.5, \mu_1 = 0, mu_2 = 1$$

Scenario 3: $$p_1 = 0.5, p_2 = 0.5, \mu_1 = 0, mu_2 = 1.5$$

Scenario 4: $$p_1 = 0.5, p_2 = 0.5, \mu_1 = 0, mu_2 = 2$$

1000 Bootstrap runs, n = 200

Scenario 1: $$p_1 = 0.3, p_2 = 0.7, \mu_1 = 0, mu_2 = 0.5$$

Scenario 2: $$p_1 = 0.3, p_2 = 0.7, \mu_1 = 0, mu_2 = 1$$

Scenario 3: $$p_1 = 0.3, p_2 = 0.7, \mu_1 = 0, mu_2 = 1.5$$

Scenario 4: $$p_1 = 0.3, p_2 = 0.7, \mu_1 = 0, mu_2 = 2$$
